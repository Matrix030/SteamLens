{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc11a89d",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ebbcad",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable progress bar for better visibility of Dask operations\n",
    "ProgressBar().register()\n",
    "\n",
    "# Load all parquet files in one call using Dask\n",
    "print(\"Reading parquet files...\")\n",
    "df = dd.read_parquet(\"top_100_parquet/*.parquet\")\n",
    "\n",
    "# Handle missing values in key columns\n",
    "df['author_playtime_forever'] = df['author_playtime_forever'].fillna(0)\n",
    "# Convert boolean voted_up to integer for aggregation (True=1, False=0)\n",
    "df['voted_up_int'] = df['voted_up'].astype('bool').astype('int')\n",
    "# Convert playtime from minutes to hours\n",
    "df['playtime_hours'] = df['author_playtime_forever'] / 60.0\n",
    "\n",
    "# Display the first few rows to verify data loading\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba791be",
   "metadata": {},
   "source": [
    "# Task 1 - Volume per Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== VOLUME PER GAME ===\")\n",
    "# Count reviews per game\n",
    "game_review_counts = df.groupby('steam_appid').size()\n",
    "game_review_counts = game_review_counts.reset_index()\n",
    "game_review_counts.columns = ['steam_appid', 'review_count']\n",
    "# Compute and sort by review count (descending)\n",
    "top_games_by_volume = game_review_counts.compute().sort_values('review_count', ascending=False).head(100)\n",
    "print(\"Top 20 games by review count:\")\n",
    "print(top_games_by_volume.head())\n",
    "print('\\n')\n",
    "print(top_games_by_volume.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa42462",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== VOLUME PER GAME (ENGLISH REVIEWS ONLY) ===\")\n",
    "# Filter for English reviews only\n",
    "english_df = df[df['review_language'] == 'english']\n",
    "# Count reviews per game\n",
    "game_review_counts = english_df.groupby('steam_appid').size()\n",
    "game_review_counts = game_review_counts.reset_index()\n",
    "game_review_counts.columns = ['steam_appid', 'review_count']\n",
    "# Compute and sort by review count (descending)\n",
    "top_games_by_volume = game_review_counts.compute().sort_values('review_count', ascending=False).head(100)\n",
    "print(\"Top 20 games by review count:\")\n",
    "print(top_games_by_volume.head(20))\n",
    "print('\\n')\n",
    "print(\"Bottom 5 of top 100:\")\n",
    "print(top_games_by_volume.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae5cf5",
   "metadata": {},
   "source": [
    "# SKIP THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Extract top 100 appids from your dataframe\n",
    "# top_100_appids = top_games_by_volume['steam_appid'].tolist()\n",
    "\n",
    "# # Source and destination\n",
    "# source_folder = 'cleaned_data_polars'\n",
    "# destination_folder = 'top_100_parquet'\n",
    "# os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# # Copy .parquet files\n",
    "# for appid in top_100_appids:\n",
    "#     src = os.path.join(source_folder, f\"{appid}.parquet\")\n",
    "#     dst = os.path.join(destination_folder, f\"{appid}.parquet\")\n",
    "#     if os.path.exists(src):\n",
    "#         shutil.copy2(src, dst)\n",
    "#         print(f\"Copied: {appid}.parquet\")\n",
    "#     else:\n",
    "#         print(f\"Missing: {appid}.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64c9ab",
   "metadata": {},
   "source": [
    "# Task 2 - Sentiment Proxy (Votes-Up Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== SENTIMENT PROXY - VOTES-UP RATIO ===\")\n",
    "# Calculate sum of positive reviews and total count per game\n",
    "sentiment_agg = df.groupby('steam_appid').agg({\n",
    "    'voted_up_int': ['sum', 'count']\n",
    "}).compute()\n",
    "\n",
    "# Process results in pandas\n",
    "sentiment_agg.columns = ['votes_up_sum', 'review_count']\n",
    "sentiment_agg['positive_ratio'] = sentiment_agg['votes_up_sum'] / sentiment_agg['review_count']\n",
    "\n",
    "# Filter games with at least 100 reviews\n",
    "top_sentiment = (\n",
    "    sentiment_agg[sentiment_agg['review_count'] >= 100]\n",
    "    .sort_values('positive_ratio', ascending=False)\n",
    "    .head(20)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Top 20 games by positive ratio (minimum 100 reviews):\")\n",
    "top_sentiment[['steam_appid', 'review_count', 'positive_ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102365c",
   "metadata": {},
   "source": [
    "# Playtime Statistics per Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2876ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== PLAY-TIME DISTRIBUTIONS ===\")\n",
    "\n",
    "# Define function to compute playtime stats for a partition of data\n",
    "def compute_playtime_stats(partition_df):\n",
    "    result = []\n",
    "    \n",
    "    # Get unique app IDs in this partition\n",
    "    app_ids = partition_df['steam_appid'].unique()\n",
    "    \n",
    "    for app_id in app_ids:\n",
    "        # Get playtime data for this app within the partition\n",
    "        app_data = partition_df[partition_df['steam_appid'] == app_id]['playtime_hours']\n",
    "        \n",
    "        if len(app_data) > 0:\n",
    "            result.append({\n",
    "                'steam_appid': app_id,\n",
    "                'count': len(app_data),\n",
    "                'sum_hours': app_data.sum(),\n",
    "                'median_hours': app_data.median(),\n",
    "                'percentile_95_hours': app_data.quantile(0.95)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "# Apply the function to each partition\n",
    "print(\"Computing playtime statistics in parallel...\")\n",
    "partition_stats = df.map_partitions(compute_playtime_stats).compute()\n",
    "\n",
    "# Simpler aggregation approach\n",
    "print(\"Combining results...\")\n",
    "playtime_stats_combined = partition_stats.groupby('steam_appid').agg({\n",
    "    'count': 'sum',\n",
    "    'sum_hours': 'sum',\n",
    "    'median_hours': 'mean',  # Approximation: average of partition medians\n",
    "    'percentile_95_hours': 'max'  # Conservative estimate: max of partition 95th percentiles\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate the mean after aggregation\n",
    "playtime_stats_combined['mean_hours'] = playtime_stats_combined['sum_hours'] / playtime_stats_combined['count']\n",
    "\n",
    "# Reorder columns for better readability\n",
    "playtime_stats_df = playtime_stats_combined[['steam_appid', 'count', 'mean_hours', 'median_hours', 'percentile_95_hours']]\n",
    "\n",
    "print(\"Playtime statistics per game (showing first 20):\")\n",
    "playtime_stats_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e7185",
   "metadata": {},
   "source": [
    "# Generate Global Playtime Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f57e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating playtime histogram...\")\n",
    "\n",
    "# For large datasets, sample to avoid memory issues\n",
    "estimated_size = df.shape[0].compute()\n",
    "\n",
    "if estimated_size > 1_000_000:\n",
    "    # Use a sampling fraction that gives us at most 1M records\n",
    "    sample_frac = min(1_000_000 / estimated_size, 1.0)\n",
    "    print(f\"Sampling {sample_frac:.2%} of data for histogram ({estimated_size:,} records)\")\n",
    "    playtime_data = df['playtime_hours'].sample(frac=sample_frac).compute()\n",
    "else:\n",
    "    # For smaller datasets, use all data\n",
    "    playtime_data = df['playtime_hours'].compute()\n",
    "\n",
    "# Filter outliers for better visualization (keep playtimes under 1000 hours)\n",
    "filtered_playtime = playtime_data[playtime_data < 1000]\n",
    "\n",
    "# Create histogram with 1-hour bins\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(filtered_playtime, bins=np.arange(0, 1000, 1), alpha=0.75)\n",
    "plt.title('Distribution of Playtime Hours (excluding outliers > 1000 hours)')\n",
    "plt.xlabel('Playtime (hours)')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add vertical lines for key statistics\n",
    "global_mean = filtered_playtime.mean()\n",
    "global_median = filtered_playtime.median()\n",
    "\n",
    "plt.axvline(global_mean, color='r', linestyle='--', label=f'Mean: {global_mean:.2f} hours')\n",
    "plt.axvline(global_median, color='g', linestyle='--', label=f'Median: {global_median:.2f} hours')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the histogram\n",
    "plt.savefig('playtime_hist.png', dpi=300)\n",
    "print(\"Histogram saved as 'playtime_hist.png'\")\n",
    "\n",
    "# Display the plot in the notebook\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "%pip install bertopic sentence-transformers umap-learn hdbscan dask[dataframe] pyarrow\n",
    "%pip install plotly  # For visualizations\n",
    "%mkdir -p models outputs  # Create directories for outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68edfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set up logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load all parquet files with Dask\n",
    "logger.info(\"Loading parquet files...\")\n",
    "df = dd.read_parquet(\"top_100_parquet/*.parquet\")\n",
    "df = df[df['review_language'] == 'english']\n",
    "# Check the shape before sampling\n",
    "total_rows = len(df)\n",
    "logger.info(f\"Total rows before sampling: {total_rows}\")\n",
    "\n",
    "# Sample 10% of the data and convert to pandas\n",
    "# Using random_state for reproducibility\n",
    "logger.info(\"Sampling data...\")\n",
    "df_sample = df.sample(frac=0.1, random_state=42).compute()\n",
    "\n",
    "logger.info(f\"Sample shape: {df_sample.shape}\")\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ba2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text by removing URLs, emojis, and special characters\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    \n",
    "    # Remove emojis (simple approach)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U000024C2-\\U0000257F\"  # Enclosed characters\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply cleaning function and filter short reviews\n",
    "logger.info(\"Cleaning text data...\")\n",
    "df_sample['clean_review'] = df_sample['review'].apply(clean_text)\n",
    "\n",
    "# Filter reviews that are too short (less than 20 characters)\n",
    "logger.info(\"Filtering short reviews...\")\n",
    "df_sample = df_sample[df_sample['clean_review'].str.len() >= 20].reset_index(drop=True)\n",
    "\n",
    "logger.info(f\"Shape after cleaning: {df_sample.shape}\")\n",
    "df_sample[['review', 'clean_review']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "# Set up the embedding model\n",
    "logger.info(\"Loading sentence transformer model...\")\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Set up UMAP for dimensionality reduction\n",
    "logger.info(\"Configuring UMAP...\")\n",
    "umap_model = umap.UMAP(\n",
    "    n_components=5,      # Dimension of the low dimensional space\n",
    "    n_neighbors=15,      # Size of local neighborhood\n",
    "    min_dist=0.0,        # Minimum distance between points in low dimensional space\n",
    "    metric='cosine',     # Distance metric\n",
    "    random_state=42      # For reproducibility\n",
    ")\n",
    "\n",
    "# Set up HDBSCAN for clustering\n",
    "logger.info(\"Configuring HDBSCAN...\")\n",
    "hdbscan_model = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=20,     # Minimum size of clusters\n",
    "    metric='euclidean',      # Distance metric\n",
    "    cluster_selection_method='eom',  # Excess of Mass algorithm\n",
    "    prediction_data=True     # Required for predicting new examples\n",
    ")\n",
    "\n",
    "# Set up BERTopic\n",
    "logger.info(\"Configuring BERTopic...\")\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    top_n_words=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Prepare corpus for topic modeling\n",
    "corpus = df_sample['clean_review'].tolist()\n",
    "\n",
    "# Fit the model and transform to get topic assignments\n",
    "logger.info(\"Fitting BERTopic model...\")\n",
    "topics, probs = topic_model.fit_transform(corpus)\n",
    "\n",
    "# Add topics to the dataframe\n",
    "df_sample['topic'] = topics\n",
    "\n",
    "logger.info(f\"Number of topics found: {len(set(topics))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05de2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top topics\n",
    "logger.info(\"Top topics:\")\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info.head(10))\n",
    "\n",
    "# For each of the first 5 topics (excluding -1 which is outliers), print example reviews\n",
    "logger.info(\"Example reviews for top topics:\")\n",
    "\n",
    "# Get list of topics excluding -1 (outliers)\n",
    "top_topics = [topic for topic in topic_info['Topic'].tolist() if topic != -1][:5]\n",
    "\n",
    "for topic in top_topics:\n",
    "    print(f\"\\n\\n--- TOPIC {topic}: {', '.join(word for word, _ in topic_model.get_topic(topic)[:5])} ---\")\n",
    "    \n",
    "    # Get indices of documents in this topic\n",
    "    doc_indices = [i for i, t in enumerate(topics) if t == topic]\n",
    "    \n",
    "    # Print 3 example reviews (or fewer if there aren't 3)\n",
    "    samples = min(3, len(doc_indices))\n",
    "    for i in range(samples):\n",
    "        idx = doc_indices[i]\n",
    "        # Print truncated version of the review for readability\n",
    "        review_text = df_sample.iloc[idx]['clean_review']\n",
    "        print(f\"Example {i+1}: {review_text[:200]}...\" if len(review_text) > 200 else f\"Example {i+1}: {review_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a900f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"  # Set default renderer for Jupyter\n",
    "\n",
    "# Create topic frequency bar chart\n",
    "logger.info(\"Generating topic frequency visualization...\")\n",
    "fig1 = topic_model.visualize_barchart(top_n_topics=10)\n",
    "fig1.write_html(\"outputs/topic_barchart.html\")\n",
    "fig1\n",
    "\n",
    "# Create UMAP 2D scatter plot\n",
    "logger.info(\"Generating UMAP topic visualization...\")\n",
    "fig2 = topic_model.visualize_topics()\n",
    "fig2.write_html(\"outputs/topics_scatter.html\")\n",
    "fig2\n",
    "\n",
    "# Try a different visualization instead\n",
    "logger.info(\"Generating hierarchical topic visualization...\")\n",
    "try:\n",
    "    # Try hierarchical topic visualization\n",
    "    fig3 = topic_model.visualize_hierarchy()\n",
    "    fig3.write_html(\"outputs/topics_hierarchy.html\")\n",
    "    fig3\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Hierarchical visualization failed: {e}\")\n",
    "    \n",
    "    # If that fails, try document visualization\n",
    "    try:\n",
    "        logger.info(\"Trying document visualization instead...\")\n",
    "        fig3 = topic_model.visualize_documents(df_sample['clean_review'])\n",
    "        fig3.write_html(\"outputs/document_viz.html\")\n",
    "        fig3\n",
    "    except Exception as e2:\n",
    "        logger.warning(f\"Document visualization also failed: {e2}\")\n",
    "        print(\"Skipping third visualization due to compatibility issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc25ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze if certain game features correlate with specific topics\n",
    "logger.info(\"Analyzing game features by topic...\")\n",
    "\n",
    "# Key features to analyze\n",
    "features = ['categories', 'genres', 'voted_up', 'author_playtime_forever', 'achievements']\n",
    "\n",
    "# Create summary statistics for each topic\n",
    "topic_stats = {}\n",
    "\n",
    "for topic in set(topics):\n",
    "    if topic == -1:  # Skip outliers\n",
    "        continue\n",
    "        \n",
    "    # Get data for this topic\n",
    "    topic_data = df_sample[df_sample['topic'] == topic]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'count': len(topic_data),\n",
    "        'avg_playtime': topic_data['author_playtime_forever'].mean(),\n",
    "        'pct_positive': (topic_data['voted_up'] == True).mean() * 100,\n",
    "    }\n",
    "    \n",
    "    # Get top genres and categories\n",
    "    if 'genres' in topic_data.columns:\n",
    "        # Flatten the list of genres\n",
    "        all_genres = []\n",
    "        for genres_list in topic_data['genres'].dropna():\n",
    "            if isinstance(genres_list, list):\n",
    "                all_genres.extend(genres_list)\n",
    "        \n",
    "        # Count occurrences\n",
    "        from collections import Counter\n",
    "        genre_counts = Counter(all_genres)\n",
    "        stats['top_genres'] = genre_counts.most_common(3)\n",
    "    \n",
    "    topic_stats[topic] = stats\n",
    "\n",
    "# Display statistics for top topics\n",
    "for topic in top_topics:\n",
    "    if topic in topic_stats:\n",
    "        print(f\"\\nTopic {topic} Statistics:\")\n",
    "        print(f\"Count: {topic_stats[topic]['count']}\")\n",
    "        print(f\"Average Playtime: {topic_stats[topic]['avg_playtime']:.1f} hours\")\n",
    "        print(f\"Percentage Positive: {topic_stats[topic]['pct_positive']:.1f}%\")\n",
    "        if 'top_genres' in topic_stats[topic]:\n",
    "            print(\"Top Genres:\", topic_stats[topic]['top_genres'])\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "logger.info(\"Saving BERTopic model...\")\n",
    "topic_model.save(\"models/bertopic_steam\")\n",
    "\n",
    "# Save topic assignments\n",
    "logger.info(\"Saving topic assignments...\")\n",
    "df_sample[['review', 'clean_review', 'topic']].to_csv(\"outputs/topic_labels.csv\", index=False)\n",
    "\n",
    "# Save topic information\n",
    "topic_model.get_topic_info().to_csv(\"outputs/topic_info.csv\", index=False)\n",
    "\n",
    "# Save topic words\n",
    "all_topics = {}\n",
    "for topic in set(topics):\n",
    "    if topic != -1:  # Skip outliers\n",
    "        all_topics[topic] = topic_model.get_topic(topic)\n",
    "        \n",
    "import json\n",
    "with open(\"outputs/topic_words.json\", \"w\") as f:\n",
    "    # Convert to a more JSON-friendly format\n",
    "    json_friendly = {str(k): [{\"word\": w, \"score\": s} for w, s in v] for k, v in all_topics.items()}\n",
    "    json.dump(json_friendly, f, indent=2)\n",
    "\n",
    "logger.info(\"All artifacts saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509643f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a simple HTML report\n",
    "logger.info(\"Generating HTML report...\")\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "    <title>Steam Reviews Topic Analysis</title>\n",
    "    <style>\n",
    "        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }\n",
    "        h1 { color: #333; }\n",
    "        .topic { margin-bottom: 30px; border: 1px solid #ddd; padding: 20px; border-radius: 5px; }\n",
    "        .keywords { color: #1a73e8; font-weight: bold; }\n",
    "        .stats { color: #666; }\n",
    "        .example { background-color: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Steam Reviews Topic Analysis</h1>\n",
    "    <p>This report presents the key topics discovered in Steam game reviews.</p>\n",
    "\"\"\"\n",
    "\n",
    "# Add topics to the report\n",
    "for topic in top_topics:\n",
    "    if topic in topic_stats:\n",
    "        # Get topic words\n",
    "        topic_words = [word for word, _ in topic_model.get_topic(topic)[:10]]\n",
    "        \n",
    "        # Get example reviews\n",
    "        doc_indices = [i for i, t in enumerate(topics) if t == topic][:3]\n",
    "        examples = [df_sample.iloc[idx]['clean_review'][:300] + \"...\" for idx in doc_indices]\n",
    "        \n",
    "        html += f\"\"\"\n",
    "        <div class=\"topic\">\n",
    "            <h2>Topic {topic}</h2>\n",
    "            <p class=\"keywords\">Keywords: {', '.join(topic_words)}</p>\n",
    "            <p class=\"stats\">\n",
    "                Number of reviews: {topic_stats[topic]['count']}<br>\n",
    "                Average playtime: {topic_stats[topic]['avg_playtime']:.1f} hours<br>\n",
    "                Percentage positive: {topic_stats[topic]['pct_positive']:.1f}%\n",
    "            </p>\n",
    "            <h3>Example Reviews:</h3>\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, example in enumerate(examples):\n",
    "            html += f'<div class=\"example\">{example}</div>'\n",
    "        \n",
    "        html += \"</div>\"\n",
    "\n",
    "html += \"\"\"\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Write HTML report\n",
    "with open(\"outputs/topic_report.html\", \"w\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "logger.info(\"HTML report generated at 'outputs/topic_report.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5b7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70eba81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
