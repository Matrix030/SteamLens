{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f13561",
   "metadata": {},
   "source": [
    "# This code has dynamic allocation of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeff0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modified Cell 1: Dynamic resource allocation for Dask Client\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from tqdm.auto import tqdm\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "\n",
    "# Dynamically determine system resources\n",
    "def get_system_resources():\n",
    "    # Get available memory (in GB)\n",
    "    total_memory = psutil.virtual_memory().total / (1024**3)\n",
    "    # Get CPU count\n",
    "    cpu_count = psutil.cpu_count(logical=False)  # Physical cores only\n",
    "    if not cpu_count:\n",
    "        cpu_count = psutil.cpu_count(logical=True)  # Logical if physical not available\n",
    "    \n",
    "    # Use 70% of available memory for Dask, split across workers\n",
    "    dask_memory = int(total_memory * 0.7)\n",
    "    # Determine optimal worker count (leave at least 1 core for system)\n",
    "    worker_count = max(1, cpu_count - 1)\n",
    "    # Memory per worker\n",
    "    memory_per_worker = int(dask_memory / worker_count)\n",
    "    \n",
    "    return {\n",
    "        'worker_count': worker_count,\n",
    "        'memory_per_worker': memory_per_worker,\n",
    "        'total_memory': total_memory\n",
    "    }\n",
    "\n",
    "# Get system resources\n",
    "resources = get_system_resources()\n",
    "print(f\"System has {resources['total_memory']:.1f}GB memory and {resources['worker_count']} CPU cores\")\n",
    "print(f\"Allocating {resources['worker_count']} workers with {resources['memory_per_worker']}GB each\")\n",
    "\n",
    "# Start a local Dask cluster with dynamically determined resources\n",
    "cluster = LocalCluster(\n",
    "    n_workers=resources['worker_count'],\n",
    "    threads_per_worker=2,\n",
    "    memory_limit=f\"{resources['memory_per_worker']}GB\"\n",
    ")\n",
    "client = Client(cluster)\n",
    "print(f\"Dashboard link: {client.dashboard_link}\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54250fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Theme Dictionary & Optimize Theme Embeddings\n",
    "# Load per-game theme keywords\n",
    "with open('game_themes.json', 'r') as f:\n",
    "    raw = json.load(f)\n",
    "GAME_THEMES = {int(appid): themes for appid, themes in raw.items()}\n",
    "\n",
    "# Initialize SBERT embedder\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to get theme embeddings for specific app IDs\n",
    "# This avoids loading all embeddings at once\n",
    "def get_theme_embeddings(app_ids):\n",
    "    \"\"\"Get theme embeddings for a specific set of app IDs\"\"\"\n",
    "    embeddings = {}\n",
    "    for appid in app_ids:\n",
    "        if appid not in embeddings and appid in GAME_THEMES:\n",
    "            emb_list = []\n",
    "            for theme, seeds in GAME_THEMES[appid].items():\n",
    "                seed_emb = embedder.encode(seeds, convert_to_numpy=True)\n",
    "                emb_list.append(seed_emb.mean(axis=0))\n",
    "            embeddings[appid] = np.vstack(emb_list)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8528a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modified Cell 3: Dynamic blocksize for reading Parquet Files\n",
    "# Estimate dataset size first\n",
    "def estimate_dataset_size(path):\n",
    "    import os\n",
    "    total_size = 0\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.parquet'):\n",
    "            file_path = os.path.join(path, file)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "    return total_size / (1024**3)  # Convert to GB\n",
    "\n",
    "# Estimate dataset size\n",
    "dataset_path = 'parquet_output_indie'\n",
    "estimated_size = estimate_dataset_size(dataset_path)\n",
    "print(f\"Estimated dataset size: {estimated_size:.2f}GB\")\n",
    "\n",
    "# Dynamically determine blocksize based on dataset and memory\n",
    "# Use smaller blocks for larger datasets to prevent memory issues\n",
    "if estimated_size > 100:  # Very large dataset\n",
    "    blocksize = '16MB'\n",
    "elif estimated_size > 10:  # Medium-large dataset\n",
    "    blocksize = '32MB'\n",
    "else:  # Smaller dataset\n",
    "    blocksize = '64MB'\n",
    "\n",
    "print(f\"Using dynamic blocksize: {blocksize}\")\n",
    "\n",
    "# Read with dynamic blocksize\n",
    "ddf = dd.read_parquet(\n",
    "    f'{dataset_path}/*.parquet',\n",
    "    columns=['steam_appid', 'review', 'review_language', 'voted_up'],\n",
    "    blocksize=blocksize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Filter & Clean Data\n",
    "# Keep only English reviews and drop missing text\n",
    "ddf = ddf[ddf['review_language'] == 'english']\n",
    "ddf = ddf.dropna(subset=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5: Optimized Partition-wise Topic Assignment\n",
    "def assign_topic(df_partition):\n",
    "    \"\"\"Assign topics using only theme embeddings for app IDs in this partition\"\"\"\n",
    "    # If no rows, return as-is\n",
    "    if df_partition.empty:\n",
    "        df_partition['topic_id'] = []\n",
    "        return df_partition\n",
    "    \n",
    "    # Get unique app IDs in this partition\n",
    "    app_ids = df_partition['steam_appid'].unique().tolist()\n",
    "    app_ids = [int(appid) for appid in app_ids]\n",
    "    \n",
    "    # Get embeddings only for app IDs in this partition\n",
    "    local_theme_embeddings = get_theme_embeddings(app_ids)\n",
    "    \n",
    "    reviews = df_partition['review'].tolist()\n",
    "    # Compute embeddings in one go with batching\n",
    "    review_embeds = embedder.encode(reviews, convert_to_numpy=True, batch_size=64)\n",
    "    \n",
    "    # Assign each review to its game-specific theme\n",
    "    topic_ids = []\n",
    "    for idx, appid in enumerate(df_partition['steam_appid']):\n",
    "        appid = int(appid)\n",
    "        if appid in local_theme_embeddings:\n",
    "            theme_embs = local_theme_embeddings[appid]\n",
    "            sims = cosine_similarity(review_embeds[idx:idx+1], theme_embs)\n",
    "            topic_ids.append(int(sims.argmax()))\n",
    "        else:\n",
    "            # Default topic if theme embeddings not available\n",
    "            topic_ids.append(0)\n",
    "    \n",
    "    df_partition['topic_id'] = topic_ids\n",
    "    return df_partition\n",
    "\n",
    "# Apply to each partition; specify output metadata\n",
    "meta = ddf._meta.assign(topic_id=np.int64())\n",
    "ddf_with_topic = ddf.map_partitions(assign_topic, meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c9617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Cell 6: Dynamic batch sizing for aggregation\n",
    "# Get unique app IDs\n",
    "unique_app_ids = ddf['steam_appid'].unique().compute()\n",
    "total_app_ids = len(unique_app_ids)\n",
    "\n",
    "# Dynamically determine batch size based on number of app IDs and memory\n",
    "# For larger datasets, use smaller batches to avoid memory issues\n",
    "if total_app_ids > 1000:  # Very large number of app IDs\n",
    "    batch_size = 3\n",
    "elif total_app_ids > 500:  # Medium-large number\n",
    "    batch_size = 5\n",
    "elif total_app_ids > 100:  # Medium number\n",
    "    batch_size = 10\n",
    "else:  # Smaller number\n",
    "    batch_size = 20\n",
    "\n",
    "print(f\"Processing {total_app_ids} unique app IDs with batch size {batch_size}\")\n",
    "\n",
    "# Initialize empty dataframes for results\n",
    "all_agg_dfs = []\n",
    "all_review_dfs = []\n",
    "\n",
    "# Process in dynamically sized batches\n",
    "for i in tqdm(range(0, len(unique_app_ids), batch_size)):\n",
    "    batch_app_ids = unique_app_ids[i:i+batch_size]\n",
    "    \n",
    "    # Filter data for this batch of app IDs\n",
    "    batch_ddf = ddf_with_topic[ddf_with_topic['steam_appid'].isin(batch_app_ids)]\n",
    "    \n",
    "    # Aggregate for this batch\n",
    "    agg = batch_ddf.groupby(['steam_appid', 'topic_id']).agg(\n",
    "        review_count=('review', 'count'),\n",
    "        likes_sum=('voted_up', 'sum')\n",
    "    )\n",
    "    \n",
    "    # Collect reviews for this batch\n",
    "    reviews_series = batch_ddf.groupby(['steam_appid', 'topic_id'])['review'] \\\n",
    "        .apply(lambda x: list(x), meta=('review', object))\n",
    "    \n",
    "    # Compute both in parallel\n",
    "    agg_df, reviews_df = dd.compute(agg, reviews_series)\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    agg_df = agg_df.reset_index()\n",
    "    reviews_df = reviews_df.reset_index().rename(columns={'review': 'Reviews'})\n",
    "    \n",
    "    # Append to results\n",
    "    all_agg_dfs.append(agg_df)\n",
    "    all_review_dfs.append(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48de627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 7: Construct Final Report DataFrame\n",
    "# Merge counts, likes, and reviews\n",
    "report_df = pd.merge(\n",
    "    agg_df,\n",
    "    reviews_df,\n",
    "    on=['steam_appid', 'topic_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Build the final output structure\n",
    "rows = []\n",
    "for _, row in report_df.iterrows():\n",
    "    appid = int(row['steam_appid'])\n",
    "    tid = int(row['topic_id'])\n",
    "    \n",
    "    # Check if appid exists in GAME_THEMES\n",
    "    if appid in GAME_THEMES:\n",
    "        theme_keys = list(GAME_THEMES[appid].keys())\n",
    "        # Check if tid is a valid index\n",
    "        if tid < len(theme_keys):\n",
    "            theme_name = theme_keys[tid]\n",
    "        else:\n",
    "            theme_name = f\"Unknown Theme {tid}\"\n",
    "    else:\n",
    "        theme_name = f\"Unknown Theme {tid}\"\n",
    "    \n",
    "    total = int(row['review_count'])\n",
    "    likes = int(row['likes_sum'])\n",
    "    like_ratio = f\"{(likes / total * 100):.1f}%\" if total > 0 else '0%'\n",
    "    rows.append({\n",
    "        'steam_appid': appid,\n",
    "        'Theme': theme_name,\n",
    "        '#Reviews': total,\n",
    "        'LikeRatio': like_ratio,\n",
    "        'Reviews': row['Reviews']\n",
    "    })\n",
    "\n",
    "final_report = pd.DataFrame(rows)\n",
    "\n",
    "# Save intermediate results to avoid recomputation if summarization fails\n",
    "final_report.to_csv('output_csvs/SBERT_DD_new_report.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ed1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: View the Report\n",
    "# Print preview of the DataFrame (excluding the Reviews column as it contains lists)\n",
    "print(\"Final report preview (Reviews column contains lists of review texts):\")\n",
    "print(final_report[['steam_appid', 'Theme', '#Reviews', 'LikeRatio']].head())\n",
    "\n",
    "# Verify that Reviews column contains lists\n",
    "sample_reviews = final_report['Reviews'].iloc[0]\n",
    "print(f\"\\nSample from first Reviews entry (showing first review only):\")\n",
    "if isinstance(sample_reviews, list) and len(sample_reviews) > 0:\n",
    "    print(f\"Number of reviews in list: {len(sample_reviews)}\")\n",
    "    print(f\"First review (truncated): {sample_reviews[0][:100]}...\")\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6242442",
   "metadata": {},
   "source": [
    "# Tuned for my hardware 1m 50 secs inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Hardware-optimized GPU summarization with Dask - Tuned for Ryzen 9700X & RTX 4080 Super\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "\n",
    "# Create checkpoint directory if it doesn't exist (minimal overhead)\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "# Optimized configuration for your specific hardware\n",
    "# RTX 4080 Super (12GB usable VRAM) + Ryzen 9700X + 20GB usable RAM\n",
    "HARDWARE_CONFIG = {\n",
    "    'worker_count': 6,                # Optimal for Ryzen 9700X\n",
    "    'memory_per_worker': '3GB',       # 18GB total for workers, leaving headroom\n",
    "    'gpu_batch_size': 96,             # Aggressive batch size for RTX 4080 Super\n",
    "    'model_name': 'sshleifer/distilbart-cnn-12-6',  # Best model for your GPU\n",
    "    'chunk_size': 400,                # Larger chunks for faster processing\n",
    "    'checkpoint_frequency': 25,       # Less frequent checkpoints for speed\n",
    "    'cleanup_frequency': 10,          # Less frequent memory cleanup\n",
    "}\n",
    "\n",
    "print(f\"Starting optimized Dask cluster for Ryzen 9700X + RTX 4080 Super configuration\")\n",
    "cluster = LocalCluster(\n",
    "    n_workers=HARDWARE_CONFIG['worker_count'], \n",
    "    threads_per_worker=2,\n",
    "    memory_limit=HARDWARE_CONFIG['memory_per_worker']\n",
    ")\n",
    "client = Client(cluster)\n",
    "print(f\"Dask dashboard available at: {client.dashboard_link}\")\n",
    "\n",
    "# Determine optimal partition sizes - larger for better throughput\n",
    "@dask.delayed\n",
    "def prepare_partition(start_idx, end_idx):\n",
    "    \"\"\"Prepare a partition optimized for high-end hardware\"\"\"\n",
    "    return final_report.iloc[start_idx:end_idx].copy()\n",
    "\n",
    "# Create larger partitions for better throughput\n",
    "n_workers = HARDWARE_CONFIG['worker_count']\n",
    "partition_size = len(final_report) // n_workers\n",
    "partitions = []\n",
    "for i in range(n_workers):\n",
    "    start_idx = i * partition_size\n",
    "    end_idx = (i + 1) * partition_size if i < n_workers - 1 else len(final_report)\n",
    "    partitions.append(prepare_partition(start_idx, end_idx))\n",
    "    print(f\"Prepared partition {i+1} with {end_idx-start_idx} items\")\n",
    "\n",
    "# Optimized worker function with aggressive resource usage\n",
    "@dask.delayed\n",
    "def process_partition(partition_df, worker_id):\n",
    "    \"\"\"Optimized worker for RTX 4080 Super\"\"\"\n",
    "    # Import needed packages\n",
    "    from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "    import torch\n",
    "    \n",
    "    # Load model components with optimal settings for RTX 4080 Super\n",
    "    print(f\"Worker {worker_id} initializing with optimized settings for RTX 4080 Super\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(HARDWARE_CONFIG['model_name'])\n",
    "    \n",
    "    # Load model with optimized settings for RTX 4080 Super\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        HARDWARE_CONFIG['model_name'],\n",
    "        torch_dtype=torch.float16,        # Half precision for speed\n",
    "        device_map=\"auto\",                # Automatic device placement\n",
    "        low_cpu_mem_usage=True            # Optimized memory usage\n",
    "    )\n",
    "    \n",
    "    # Create optimized pipeline\n",
    "    summarizer = pipeline(\n",
    "        task='summarization',\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        framework='pt',\n",
    "        model_kwargs={\n",
    "            \"use_cache\": True,            # Enable caching for speed\n",
    "            \"return_dict_in_generate\": True  # More efficient generation\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Report GPU status\n",
    "    gpu_mem = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "    print(f\"Worker {worker_id}: GPU Memory: {gpu_mem:.2f}GB allocated\")\n",
    "    \n",
    "    # Highly optimized batch processing function\n",
    "    def process_chunks_batched(chunks):\n",
    "        \"\"\"Process chunks in large batches for RTX 4080 Super\"\"\"\n",
    "        all_summaries = []\n",
    "        \n",
    "        # Use large batches for the RTX 4080 Super\n",
    "        for i in range(0, len(chunks), HARDWARE_CONFIG['gpu_batch_size']):\n",
    "            batch = chunks[i:i+HARDWARE_CONFIG['gpu_batch_size']]\n",
    "            batch_summaries = summarizer(\n",
    "                batch,\n",
    "                max_length=60,\n",
    "                min_length=20,\n",
    "                truncation=True,\n",
    "                do_sample=False,\n",
    "                num_beams=2  # Use beam search for better quality with minimal speed impact\n",
    "            )\n",
    "            all_summaries.extend([s[\"summary_text\"] for s in batch_summaries])\n",
    "            \n",
    "            # Minimal cleanup - only when really needed\n",
    "            if i % (HARDWARE_CONFIG['gpu_batch_size'] * 3) == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                    \n",
    "        return all_summaries\n",
    "    \n",
    "    # Optimized hierarchical summary function\n",
    "    def hierarchical_summary(reviews):\n",
    "        \"\"\"Create hierarchical summary with optimized chunk sizes\"\"\"\n",
    "        # Handle edge cases efficiently\n",
    "        if not reviews or not isinstance(reviews, list):\n",
    "            return \"No reviews available for summarization.\"\n",
    "        \n",
    "        # Fast path for small review sets\n",
    "        if len(reviews) <= HARDWARE_CONFIG['chunk_size']:\n",
    "            doc = \"\\n\\n\".join(reviews)\n",
    "            return summarizer(\n",
    "                doc,\n",
    "                max_length=60,\n",
    "                min_length=20,\n",
    "                truncation=True,\n",
    "                do_sample=False\n",
    "            )[0]['summary_text']\n",
    "        \n",
    "        # Process larger review sets with optimized chunking\n",
    "        all_chunks = []\n",
    "        for i in range(0, len(reviews), HARDWARE_CONFIG['chunk_size']):\n",
    "            batch = reviews[i:i+HARDWARE_CONFIG['chunk_size']]\n",
    "            text = \"\\n\\n\".join(batch)\n",
    "            all_chunks.append(text)\n",
    "        \n",
    "        # Process chunks with optimized batching\n",
    "        intermediate_summaries = process_chunks_batched(all_chunks)\n",
    "        \n",
    "        # Create final summary\n",
    "        joined = \" \".join(intermediate_summaries)\n",
    "        return summarizer(\n",
    "            joined,\n",
    "            max_length=60,\n",
    "            min_length=20,\n",
    "            truncation=True,\n",
    "            do_sample=False\n",
    "        )[0]['summary_text']\n",
    "    \n",
    "    # Process the partition with minimal overhead\n",
    "    results = []\n",
    "    \n",
    "    # Use tqdm for progress tracking\n",
    "    with tqdm(total=len(partition_df), desc=f\"Worker {worker_id}\", position=worker_id) as pbar:\n",
    "        for idx, row in partition_df.iterrows():\n",
    "            # Process the review\n",
    "            summary = hierarchical_summary(row['Reviews'])\n",
    "            results.append((idx, summary))\n",
    "            \n",
    "            # Minimal cleanup - only every N iterations\n",
    "            if len(results) % HARDWARE_CONFIG['cleanup_frequency'] == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Final cleanup\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Worker {worker_id} completed successfully\")\n",
    "    return results\n",
    "\n",
    "# Schedule tasks\n",
    "print(f\"Scheduling {n_workers} optimized partitions...\")\n",
    "delayed_results = []\n",
    "for i in range(n_workers):\n",
    "    delayed_result = process_partition(partitions[i], i)\n",
    "    delayed_results.append(delayed_result)\n",
    "\n",
    "# Streamlined progress tracking\n",
    "print(\"\\nStarting optimized computation...\")\n",
    "main_progress = tqdm(total=len(final_report), desc=\"Overall Progress\")\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Minimal checkpoint system - only save occasionally\n",
    "def update_main_progress(futures):\n",
    "    while not stop_flag:\n",
    "        # Count completed futures\n",
    "        completed_count = sum(f.status == 'finished' for f in futures)\n",
    "        completed_percentage = completed_count / len(futures)\n",
    "        \n",
    "        # Update progress bar\n",
    "        main_progress.n = int(len(final_report) * completed_percentage)\n",
    "        main_progress.refresh()\n",
    "        \n",
    "        # Only check every 5 seconds to reduce overhead\n",
    "        time.sleep(5)\n",
    "\n",
    "# Submit tasks to cluster\n",
    "futures = client.compute(delayed_results)\n",
    "\n",
    "# Start progress monitor with minimal overhead\n",
    "stop_flag = False\n",
    "monitor_thread = threading.Thread(target=update_main_progress, args=(futures,))\n",
    "monitor_thread.daemon = True\n",
    "monitor_thread.start()\n",
    "\n",
    "# Wait for computation\n",
    "try:\n",
    "    print(\"Computing with optimal settings for RTX 4080 Super...\")\n",
    "    results = client.gather(futures)\n",
    "except Exception as e:\n",
    "    print(f\"Error with futures: {e}\")\n",
    "    print(\"Falling back to direct computation...\")\n",
    "    results = dask.compute(*delayed_results)\n",
    "\n",
    "# Stop progress monitor\n",
    "stop_flag = True\n",
    "monitor_thread.join(timeout=3)\n",
    "\n",
    "# Update progress to completion\n",
    "main_progress.n = len(final_report)\n",
    "main_progress.refresh()\n",
    "main_progress.close()\n",
    "\n",
    "# Process results efficiently\n",
    "all_results = []\n",
    "for worker_results in results:\n",
    "    all_results.extend(worker_results)\n",
    "\n",
    "# Sort results\n",
    "all_results.sort(key=lambda x: x[0])\n",
    "summaries = [result[1] for result in all_results]\n",
    "\n",
    "# Store results\n",
    "final_report['QuickSummary'] = summaries\n",
    "\n",
    "# Report timing\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\nOptimized processing completed in {elapsed_time:.2f} seconds\")\n",
    "print(f\"Average time per item: {elapsed_time/len(final_report):.2f} seconds\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nResults sample:\")\n",
    "display(final_report[['steam_appid', 'Theme', 'QuickSummary']].head())\n",
    "\n",
    "# Save results\n",
    "final_report.to_csv('output_csvs/optimized_hardware_report.csv')\n",
    "print(\"Results saved to output_csvs/optimized_hardware_report.csv\")\n",
    "\n",
    "# Clean up\n",
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
