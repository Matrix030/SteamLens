{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e9ca96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask_ml in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (2025.1.0)\n",
      "Requirement already satisfied: dask-glm>=0.2.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask_ml) (0.3.2)\n",
      "Requirement already satisfied: dask>=2025.1.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask[array,dataframe]>=2025.1.0->dask_ml) (2025.4.1)\n",
      "Requirement already satisfied: distributed>=2025.1.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask_ml) (2025.4.1)\n",
      "Requirement already satisfied: multipledispatch>=0.4.9 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask_ml) (0.6.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask_ml) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask_ml) (2.0.2)\n",
      "Requirement already satisfied: packaging in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask_ml) (25.0)\n",
      "Requirement already satisfied: pandas>=2.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask_ml) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask_ml) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask_ml) (1.15.2)\n",
      "Requirement already satisfied: click>=8.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask_ml) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask_ml) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask_ml) (2025.3.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask_ml) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask_ml) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask_ml) (1.0.0)\n",
      "Requirement already satisfied: sparse>=0.7.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask-glm>=0.2.0->dask_ml) (0.16.0)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from dask[array,dataframe]>=2025.1.0->dask_ml) (19.0.1)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from distributed>=2025.1.0->dask_ml) (3.1.6)\n",
      "Requirement already satisfied: locket>=1.0.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from distributed>=2025.1.0->dask_ml) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from distributed>=2025.1.0->dask_ml) (1.1.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from distributed>=2025.1.0->dask_ml) (7.0.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from distributed>=2025.1.0->dask_ml) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from distributed>=2025.1.0->dask_ml) (3.1.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from distributed>=2025.1.0->dask_ml) (6.4.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from distributed>=2025.1.0->dask_ml) (2.4.0)\n",
      "Requirement already satisfied: zict>=3.0.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from distributed>=2025.1.0->dask_ml) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from jinja2>=2.10.3->distributed>=2025.1.0->dask_ml) (3.0.2)\n",
      "Requirement already satisfied: six in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from multipledispatch>=0.4.9->dask_ml) (1.17.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from numba>=0.51.0->dask_ml) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from pandas>=2.0->dask_ml) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from pandas>=2.0->dask_ml) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from pandas>=2.0->dask_ml) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from scikit-learn>=1.6.1->dask_ml) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from scikit-learn>=1.6.1->dask_ml) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rake-nltk in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (1.0.6)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from rake-nltk) (3.9.1)\n",
      "Requirement already satisfied: click in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.67.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: bertopic[all] in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (0.17.0)\n",
      "\u001b[33mWARNING: bertopic 0.17.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: hdbscan>=0.8.29 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from bertopic[all]) (0.8.40)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from bertopic[all]) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from bertopic[all]) (2.2.3)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from bertopic[all]) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from bertopic[all]) (1.6.1)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from bertopic[all]) (4.67.1)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from bertopic[all]) (0.5.7)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scipy in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from hdbscan>=0.8.29->bertopic[all]) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from pandas>=1.1.5->bertopic[all]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from pandas>=1.1.5->bertopic[all]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from pandas>=1.1.5->bertopic[all]) (2025.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from plotly>=4.7.0->bertopic[all]) (1.37.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic[all]) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from scikit-learn>=1.0->bertopic[all]) (3.6.0)\n",
      "Requirement already satisfied: setuptools in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (79.0.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from umap-learn>=0.5.0->bertopic[all]) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from umap-learn>=0.5.0->bertopic[all]) (0.5.13)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic[all]) (0.43.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rgmatr1x/anaconda3/envs/rapids-25.04/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install dask_ml\n",
    "!pip install rake-nltk\n",
    "# only if you haven't already installed these\n",
    "!pip install bertopic[all] sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad3b533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rgmatr1x/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rgmatr1x/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "# Only need to run this once per environment\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# TF–IDF dependencies\n",
    "from dask_ml.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# RAKE for key-phrases\n",
    "from rake_nltk import Rake\n",
    "\n",
    "# (Optional) summarization\n",
    "from transformers import pipeline\n",
    "\n",
    "# — your settings —\n",
    "DD_PATH        = '../Step_3_analysis/top_100_parquet/10.parquet'  # adjust as needed\n",
    "TOP_N_TERMS    = 20\n",
    "TOP_N_PHRASES  = 20\n",
    "SUMMARIZE      = True                        # set False to skip summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50571dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed‐word themes\n",
    "themes = {\n",
    "    # Core moment‑to‑moment play\n",
    "    'gameplay': [\n",
    "        'gameplay', 'mechanics', 'tactical shooter', 'precision', 'aim',\n",
    "        'headshot', 'spray‑control', 'burst‑fire', 'recoil', 'crosshair',\n",
    "        'peek', 'counter‑strafe', 'movement', 'jump‑peek', 'clutch',\n",
    "        'bomb plant', 'defuse', 'round', 'eco‑round', 'overtime'\n",
    "    ],\n",
    "\n",
    "    # Weapons, grenades, recoil patterns\n",
    "    'weapons': [\n",
    "        'weapon', 'gun', 'rifle', 'ak', 'm4', 'awp', 'pistol', 'deagle',\n",
    "        'smg', 'shotgun', 'sniper', 'knife', 'grenade', 'flashbang',\n",
    "        'smoke', 'molotov', 'he‑nade', 'incendiary', 'zeus', 'spray',\n",
    "        'pull‑out time', 'reload'\n",
    "    ],\n",
    "\n",
    "    # Map design and call‑outs\n",
    "    'maps': [\n",
    "        'map', 'layout', 'bombsite', 'call‑out', 'rotation', 'angles',\n",
    "        'cover', 'line‑up', 'utility spot', 'choke‑point', 'dust2',\n",
    "        'mirage', 'inferno', 'nuke', 'overpass', 'ancient', 'vertigo',\n",
    "        'office', 'train', 'cache'\n",
    "    ],\n",
    "\n",
    "    # Ranked play, esport angle, organised competition\n",
    "    'competitive': [\n",
    "        'competitive', 'matchmaking', 'rank', 'elo', 'premier', 'global elite',\n",
    "        'silver', 'faceit', 'esport', 'tournament', 'major', 'league',\n",
    "        'teamplay', 'strat', 'timeout', 'coach', 'demo review', 'practice'\n",
    "    ],\n",
    "\n",
    "    # Game economy, skins, trading and cases\n",
    "    'economy & skins': [\n",
    "        'economy', 'money', 'buy', 'force', 'save', 'full‑buy', 'bonus‑loss',\n",
    "        'skin', 'knife skin', 'case', 'capsule', 'stattrak', 'souvenir',\n",
    "        'sticker', 'trade‑up', 'market', 'auction', 'rarity', 'float value',\n",
    "        'pattern', 'lootbox'\n",
    "    ],\n",
    "\n",
    "    # Anti‑cheat and integrity concerns\n",
    "    'anti_cheat': [\n",
    "        'cheater', 'cheat', 'hacker', 'hack', 'wallhack', 'aimbot', 'spinbot',\n",
    "        'vac', 'vac ban', 'prime', 'overwatch', 'smurf', 'rage', 'backtracking',\n",
    "        'triggerbot', 'report', 'banwave', 'trust factor'\n",
    "    ],\n",
    "\n",
    "    # Performance, networking and technical stability\n",
    "    'performance': [\n",
    "        'fps', 'frame rate', 'stutter', 'lag', 'ping', 'tickrate', 'sub‑tick',\n",
    "        'server', 'hit‑reg', 'netcode', 'desync', 'packet loss', 'freeze',\n",
    "        'crash', 'memory leak', 'loading time', 'update', 'patch', 'driver'\n",
    "    ],\n",
    "\n",
    "    # Visual fidelity and art direction\n",
    "    'visuals': [\n",
    "        'visuals', 'graphics', 'shader', 'lighting', 'smoke effect',\n",
    "        'blood splatter', 'particle', 'texture', 'model', 'animation',\n",
    "        'ui', 'hud', 'crosshair style', 'ray tracing', 'color', 'resolution',\n",
    "        'fov', 'viewmodel'\n",
    "    ],\n",
    "\n",
    "    # Audio design and voice comms\n",
    "    'audio': [\n",
    "        'audio', 'sound', 'footstep', 'sound cue', 'directional',\n",
    "        'occlusion', 'gunshot', 'reverb', 'bomb beep', 'defuse sound',\n",
    "        'voice chat', 'callout', 'microphone', 'radio command', 'volume',\n",
    "        'sound bug', 'muffle', 'mix'\n",
    "    ],\n",
    "\n",
    "    # Social experience and community features\n",
    "    'community': [\n",
    "        'community', 'friends', 'lobby', 'party', 'team‑mate', 'toxic',\n",
    "        'grief', 'vote kick', 'chat', 'text chat', 'mute', 'spray logo',\n",
    "        'workshop', 'community server', 'surf', 'bhop', 'mods', 'plugin',\n",
    "        'custom map', 'training map'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def slugify(name):\n",
    "    return name.lower().replace(' ', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee21f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read only needed cols (add 'voted_up' for proxy pos/neg)\n",
    "df = dd.read_parquet(\n",
    "    DD_PATH,\n",
    "    columns=['review', 'votes_up', 'voted_up', 'review_language']\n",
    ")\n",
    "\n",
    "# filter to English reviews only\n",
    "df = df[df['review_language'] == 'english']\n",
    "\n",
    "# replace NaN/None, force to str, then lowercase\n",
    "df['review_text'] = (\n",
    "    df['review']\n",
    "    .fillna('')           # replace pandas NaN\n",
    "    .astype(str)          # convert any None or <NA> to string\n",
    "    .str.lower()          # lowercase\n",
    ")\n",
    "\n",
    "# cache partitions for faster reuse\n",
    "df = df.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5dc7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_df    = df[df['voted_up'] == True]\n",
    "dislikes_df = df[df['voted_up'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee4828a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-TFIDF terms (likes): ['16' '3' 'best' 'classic' 'counterstrike' 'cs' 'csgo' 'fps' 'fun' 'game'\n",
      " 'games' 'good' 'just' 'like' 'old' 'play' 'played' 'playing' 'time'\n",
      " 'years']\n",
      "Top-TFIDF terms (dislikes): ['16' 'bad' 'better' 'buy' 'counterstrike' 'cs' 'csgo' 'dont' 'game'\n",
      " 'good' 'just' 'like' 'old' 'people' 'play' 'playing' 'server' 'servers'\n",
      " 'steam' 'time']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def top_tfidf_terms_sample(ddf, N=TOP_N_TERMS, sample_size=50000, random_state=42):\n",
    "    # 1) count total docs in this bucket\n",
    "    total = ddf['review_text'].dropna().count().compute()\n",
    "    # 2) compute fraction so we sample ~sample_size docs\n",
    "    frac = min(1.0, sample_size / total)\n",
    "    # 3) sample that fraction\n",
    "    sample = (\n",
    "        ddf['review_text']\n",
    "        .dropna()\n",
    "        .sample(frac=frac, random_state=random_state)\n",
    "        .compute()\n",
    "        .tolist()\n",
    "    )\n",
    "    # 4) fit a classical TfidfVectorizer on the sampled docs\n",
    "    vect = TfidfVectorizer(\n",
    "        max_features=N,\n",
    "        stop_words='english',\n",
    "        token_pattern=r'(?u)\\b\\w+\\b'\n",
    "    )\n",
    "    X = vect.fit_transform(sample)  # (n_samples x N) sparse matrix\n",
    "    # 5) return the top-N feature names\n",
    "    return vect.get_feature_names_out()\n",
    "\n",
    "# run for likes & dislikes\n",
    "likes_top_terms    = top_tfidf_terms_sample(likes_df)\n",
    "dislikes_top_terms = top_tfidf_terms_sample(dislikes_df)\n",
    "\n",
    "print(\"Top-TFIDF terms (likes):\", likes_top_terms)\n",
    "print(\"Top-TFIDF terms (dislikes):\", dislikes_top_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78b0ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top n-grams (likes): [('game', 18505), ('best', 5587), ('good', 4234), ('old', 3747), ('play', 3154), ('cs', 2802), ('best game', 2402), ('16', 2365), ('counterstrike', 2356), ('fps', 2029), ('like', 2027), ('games', 2003), ('fun', 1949), ('time', 1937), ('playing', 1891), ('played', 1856), ('classic', 1851), ('just', 1838), ('years', 1484), ('csgo', 1474)]\n",
      "Top n-grams (dislikes): [('game', 802), ('play', 231), ('like', 168), ('just', 160), ('servers', 153), ('cs', 143), ('dont', 129), ('good', 123), ('server', 120), ('time', 105), ('better', 99), ('counterstrike', 98), ('buy', 96), ('csgo', 86), ('old', 85), ('16', 84), ('people', 82), ('playing', 79), ('steam', 79), ('bad', 76)]\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Top n-grams for actionable insights\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def top_ngrams_counts(ddf, ngram_range=(1,2), top_k=TOP_N_PHRASES,\n",
    "                      sample_size=50000, random_state=42):\n",
    "    # sample a fraction so we get ~sample_size docs\n",
    "    total = ddf.dropna().count().compute()\n",
    "    frac = min(1.0, sample_size / total)\n",
    "    sample = (\n",
    "        ddf.dropna()\n",
    "           .sample(frac=frac, random_state=random_state)\n",
    "           .compute()\n",
    "           .tolist()\n",
    "    )\n",
    "    # extract n-grams\n",
    "    vect = CountVectorizer(stop_words='english', ngram_range=ngram_range)\n",
    "    X    = vect.fit_transform(sample)\n",
    "    sums = X.sum(axis=0)\n",
    "    terms = vect.get_feature_names_out()\n",
    "    # pair up term → count\n",
    "    counts = [(terms[i], int(sums[0, i])) for i in range(len(terms))]\n",
    "    # sort and take top_k\n",
    "    return sorted(counts, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "# run on likes / dislikes\n",
    "likes_top_ngrams    = top_ngrams_counts(likes_df['review_text'])\n",
    "dislikes_top_ngrams = top_ngrams_counts(dislikes_df['review_text'])\n",
    "\n",
    "print(\"Top n-grams (likes):\", likes_top_ngrams)\n",
    "print(\"Top n-grams (dislikes):\", dislikes_top_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96ee8910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Your max_length is set to 60, but your input_length is only 37. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 60, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== What players LIKE ===\n",
      "- The best game 16 counterstrike fps like games fun time playing played classic just years csgo. The best good old play cs best.\n",
      "\n",
      "=== What players DISLIKE ===\n",
      "- 's guide on how to get the most out of your game time. The guide includes a list of tips and tricks that can be used to improve your game play.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Chunked bullet summarization for multiple insights\n",
    "from transformers import pipeline\n",
    "\n",
    "def chunk_text(doc, max_words=100):\n",
    "    \"\"\"Split `doc` into chunks of ~max_words tokens each.\"\"\"\n",
    "    words = doc.split()\n",
    "    return [\" \".join(words[i : i + max_words]) \n",
    "            for i in range(0, len(words), max_words)]\n",
    "\n",
    "if SUMMARIZE:\n",
    "    # initialize once\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    \n",
    "    def summarize_to_bullets(blob, max_bullets=5):\n",
    "        bullets = []\n",
    "        for chunk in chunk_text(blob, max_words=100):\n",
    "            prompt = \"Summarize the following into concise bullet points:\\n\\n\" + chunk\n",
    "            out = summarizer(prompt,\n",
    "                             max_length=60,\n",
    "                             min_length=20,\n",
    "                             do_sample=False)[0]['summary_text']\n",
    "            # split on newlines or “•” if present\n",
    "            lines = [line.strip(\" •-–\") \n",
    "                     for line in out.replace(\"•\",\"\\n\").splitlines() \n",
    "                     if line.strip()]\n",
    "            bullets.extend(lines)\n",
    "            if len(bullets) >= max_bullets:\n",
    "                break\n",
    "        return bullets[:max_bullets]\n",
    "    \n",
    "    # build your blobs (from previous cells)\n",
    "    likes_blob    = \" \".join(term for term, _ in likes_top_ngrams)\n",
    "    dislikes_blob = \" \".join(term for term, _ in dislikes_top_ngrams)\n",
    "    \n",
    "    # get multiple bullet insights\n",
    "    like_insights    = summarize_to_bullets(likes_blob,    max_bullets=30)\n",
    "    dislike_insights = summarize_to_bullets(dislikes_blob, max_bullets=30)\n",
    "    \n",
    "    # print them nicely\n",
    "    print(\"=== What players LIKE ===\")\n",
    "    for b in like_insights:\n",
    "        print(\"-\", b)\n",
    "    print(\"\\n=== What players DISLIKE ===\")\n",
    "    for b in dislike_insights:\n",
    "        print(\"-\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef38fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
